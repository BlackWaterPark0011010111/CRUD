# CRUD
sqlalchemy
curl
fast api

это способ создания нашего приложения с помощью Create Read Update Delete операций. то есть он должен уметь создавать,читать,обновлять и удалять состав данных.   это структурирование наших моделей для наших API.Оперирование  в стиле CRUD в базе данных и для всех наших существующих вычислительных сущностей. CRUD СООТВЕТСТВУЕТ http- МЕТОДАМ КОТОРЫЕ ИСПОЛЬЗУЮТСЯ ЧТОБЫ СООБЩИТЬ НАШЕМУ СЕРВЕру ка и что мы хотим сделать с нашим хранилищем в базе, и как мы хотим взаимодействовать с веб-сайтом:

Создать  :  POST
Читать   :  GET
Обновить :  UPDATE
Удалить  :  DELETE
наше API,которое хранит данные должно позволять нам добавлять новые записи по тому скелету,которое мы задаем для нашей базы.
в записи curl -X POST http://localhost:5000 /add -d name=Jack -d price=10

в этой записи "-Х" --это структурирование нашего запроса как запрос POST, а флаги "-d" --это сами данные которые мы отправляем в наше API. и это возвращает запись с нашими данными в формате json.


READ: позволяет просто увидеть все данные которые у нас есть в данную секунду без внесений каких либо изменений.
curl -X GET http://localhost:5000 /drinks
{ 
    "drinks":[
        {
            "id": 1
            "name":"Jack",
            "price":10
        },
        {
            "id": 2
            "name":"Jim",
            "price":10
        }
    ]
}

curl -X GET http://localhost:5000 /drinks/1

1-ца здесь выводит то что содержит идентификатор id равен 1.
то есть если мы с read просто прописываем название url без идентификатора,но в read нам уже нужен id по которому мы будем смотреть и читать то,что нам нужно вытащить.

через POST, через специальный метод http, мы создаем новые записи для внесения их в дб
sqlalchemy- это непосредственно работа с бд.
CRUD - чистое бизнес-событие.они редко бывают изолированными и их нельзя рассматривать изолированно.все проверки с правами доступа должны быть на уровне api и бд.если злоумышленник найдет способ отправить запрос в api,сможет удалить то что не должен,нужна row-level secrity, принцип defence in depth. это разделение ответственностей.
это отдельная архитектура с 4-мя endpointam`и. должно быть идемпотентным
Для read,update и delete это обычно прочитал дважды получил то же, удалил дважды и запись уже удалена. Для Create-нет.Два одинаковых POST-запроса создадут две одинаковые записи,в Rest для идемпотентности Update используют PUT вместо PATCH,потому что PUT заменяет весь ресурс,а PATCH частичное обновление.для защиты от дублирования сетевые повторы, двойные клики используют idempotency keys уникальный ключ, который клиент отправляет с запросом,сервер кэширует результат выполнения по этому ключу и на повторный запрос с тем же ключом возвращает тот же ответ, не выполняя операцию снова.
и каждая crud операция будет менять состояние системы. так же паттерны применяются для пользовательского интерфейса. валидация данных на 3х уровнях:
на клиенте(для UX)
нв уровне API(для формальной проверки типов и форматов,Pydantic схемы)
База данных будет как последний рубеж и её (ограничение которое позволяет уникально идентифицировать каждую запись в таблице) защитят от поврежденных данных.Производительность READ зависит от индексов,каждое поле по которому происходит WHERE,ORDER BY,JOIN ----должно быть проиндексировано,но если индексы замедляют insert i update потому что их нужно поддерживать--нужно  балансировать
Транзакционность-все связанные изменения в рамках одной операции--только в одной и единой транзакции----Списаниес одного счета-зачисление на другой---через BEGIN.....COMMIT(с read commited достаточно)

Пагинация и фильтрация — обязательная часть Read операций.


функция обновления (по id)


функция удаления (по id)

engine-глобальное подключение 
session-одно подключение конкретно
engine создаётся один раз при старте.
Session — для каждого HTTP-запроса своя.

не пишем базу данных внутри main файла. ---это будет зависимость. паттерны,сервисы,чистый код и тд..... это запрещено
отдельный database.py файл 
Презентационный слой API/UI --> бизнес-логика Services --> слой данных Repositories  --> База данных

async with session.begin(): для атомарных операций
запрещены f-строки --sql иньекции

всегда пагинация
        async def get_items(db, skip: int = 0, limit: int = 100):
    return await db.execute(
        select(Item).offset(skip).limit(limit)
    )



без пула при 100 параллельных запросах упадёт БД.
Контекстные менеджеры для сессий ---обязательно  with:

expire_on_commit=False - ставить ВСЕГДА в sessionmaker:
Без этой настройки после await session.commit() все объекты становятся неактивными.если потом обратиться к user.email -будет ошибка.
С этой настройкой- объекты остаются доступны.

await session.refresh()- после добавления нового объекта.при создании нового юзера,в обьекте user, не будет id,присвоенный  от базы

lazy="raise"-ставить на отношениях в моделях

раз в месяц смотреть логи-сколько соединений в пуле, сколько ждут.
если постоянно есть ожидание-увеличить pool_size.если пул почти пустой-уменьшить.

подключение к разным бд=отдельные engine:
Если проект работает с основной БД и, например, Redis:создаю ДВА engine в database.py,два sessionmaker,две зависимости get_db() и get_redis()

В development можно без SSL, в production обязательно

В production echo=False, иначе логи забьются SQL запросами

Connection string -не хардкодить:
бкз "postgresql://user:pass@localhost/db" в коде
выносить в .env,читать через os.getenv()


При shutdown закрывать engine,атооооооо останутся незакрытые соединения
@app.on_event("shutdown")
async def shutdown():
    await engine.dispose()

datetime в UTC,все даты в бд  в UTC,конвертация в локальное время только при отображении пользователю будут проблемы с летним временем, переездами......


soft delete вместо DELETE,без удаление записи физически из бд,
сделать колонку "deleted_at" или чтото.
Удаление=проставление timestamp. 
Восстановление=очистка поля.чтобы не потерять историю данных.

Раз в неделю смотреть логи бд по медленным запросам >100ms

хэшировать перед сохранением пароли

bulk insert/update:
session.bulk_insert_mappings()-в 100 раз быстрее.


SQLAlchemy использует prepared statements их автоматически.


Если планируется нагрузка,то настроить read replicas сразу,то шо  при переделывании архитектуры будет больно.

Failover стратегия:
если основная бд упала-иметь скрипт переключения на replica.тестировать раз в квартал.


при балансе счета,настройки безопасности, для критичных данных вести лог кто и когда чтро изменил на уровне бд триггеррами


 задача connection,спит 5 минут ждёт API одновременно HTTP запросы не могут получить connection из пула в таймаут.
 для фоновых задач отдельный engine с pool_size=1 или connection outside pool.


при проверке есть ли email в бд, и если нет,создаю-всего 2 запроса одновременно проверяют и видят НЕТ и оба создают. UNIQUE constraint в БД ловит, но один пользователь получает ошибку "email уже занят", хотя только что его вводил. Надо ловить IntegrityError и retry


при long polling запросы висят 30-60 секунд забирают connection из пула. БД столько не тянет.нужно WebSockets или отдельный сервер/протокол