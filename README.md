# CRUD

это концептуальный паттерн описывающий четыре фундаментальные операции над данными.И реализация служит помощью в в работе с API. Оперирование  в стиле CRUD в базе данных и для всех наших существующих вычислительных
сущностей.
если говорить в контексте RESTful API,то операции CRUD часто реализуются через соответствующие HTTP-методы, которые указывают серверу на наше намерение:

Создать  :  POST
Читать   :  GET
Обновить :  PUT(полная замена)/PATCH(частичная)
Удалить  :  DELETE

Наше API,которое хранит данные должно позволять нам добавлять новые записи по тому скелету,которое мы задаем в нашей базе.

в записи curl -X POST http://localhost:5000 /add -d name=Jack -d price=10---- в этой записи "-Х POST" указывает серверу curl использовать метод HTTP POST, а опции "-d" --это сами данные,тело запроса, которое мы отправляем в наше API в паре ключ=значение. и это возвращает запись с нашими данными в формате json.


READ: позволяет просто увидеть все данные которые у нас есть в данную секунду без внесений каких либо изменений.
curl -X GET http://localhost:5000 /drinks

{ 
    "drinks":[
        {
            "id": 1
            "name":"Jack",
            "price":10
        },
        {
            "id": 2
            "name":"Jim",
            "price":10  
        }
    ]
}

curl -X GET http://localhost:5000 /drinks/1    ----  1-ца здесь выводит то, что содержит идентификатор id равен 1.

то есть если мы с read просто прописываем название url без идентификатора,но в read нам уже нужен id по которому мы будем смотреть и читать то,что нам
нужно вытащить.
Сущности в системе имеют жизненный цикл со состояниями. Операции Update и Delete, реализующие CRUD, могут использоваться для перевода сущности из одного состояния в другое в рамках бизнес-логики (workflow). Операция Create (обычно через HTTP POST) инициализирует этот жизненный цикл, создавая запись с начальным состоянием.

sqlalchemy- это непосредственно работа с бд.

CRUD-операции являются триггерами для бизнес-событий(domain events).они редко бывают изолированными и их нельзя рассматривать изолированно,в отрыве от контекста системы.все проверки с правами доступа должны быть на уровне
api и бд.если злоумышленник найдет способ отправить запрос в api,сможет удалить то что не должен,нужна row-level security, принцип defense in depth. это
разделение ответственностей.
Реализация CRUD-операций часто воплощается в REST API через набор endpoint'ов,базовыми из которых являются четыре: POST,GET,PUT/PATCH,DELETE для ресурса, например /users.и проектирование этих endpoint`ов должно стремится к идемпотентности.
каждая crud операция должна отображать грань намерения,если при UPDATE идет исправление опечатки,то это не должно влечь за собой полную замену документа
или при обновлении аватара(только через узкий endpoint PATCH/user/{id}/avatar),не отправлять в изменение весь профиль.это только через узкий endpoint
через дизайн API.
Каналы утечки бизнес-логики по выстроенным endpoint`ам,ихние поля и какие обязательны к заполнению а какие нет  
API-это как публичная декларация о том как устроен мой бизнес и каждый endpoint и поле в схеме это будет поводом утечки информации. и изучив мою openAPI-
спецификацию,составить карту внутренностей,всех процессов.
к Примеру:
поле  status обязательное  и при создании принимает значения:
"new", "cooking", "on_way", "delivered", "cancelled"
cancelled - это side-ветка.может выйти из new или cooking.
И уязвимость поля status,поскольку оно обязательное при создании,можно создать сущность status: "delivered" и сразу получить заказ,минуя кухню и курьера.
и система принимающая такой запрос,она либо совершает ошибку либо вынуждена ставить костыли. 
если создание заказа будет через POST/orders,где user_id будет браться из токена а цена и статус (status = "pending_payment")будет вычисляться
на сервере.после проверки ресторана и позиции в меню и акции и при ошибке возвращает валидацию. пока статус "pending_payment" заказ будет существовать,но
не подтвержден и ждемс оплату или отмену. при успешной оплате клиент вызывает POST /orders/{id}/confirm-payment и бэкенд меняет статус на accepted, если
ресторан открыт или на "new" если нужно дождаться ответа от ресторана.
если отменяем заказ -->POST /orders/{id}/confirm-payment  ---> переводим в статус cancelled и сохраняется опциональная причина в логах,переводится в поле
reason.для внутренних переходов статусов используем POST /orders/{id}/status- он будет endpoint`ом доступным только для ресторана или админов и выполнять
переходы только по описанному workflow. вся линейная цепочка не выставлена наружу и больше не очевидна,и видны не состояния а действия.сама машина
состояний инкапсулирована внутри бэкенда в сервис-слое. Поля которые система определяет сама как status,total_price,final_price, не будут приниматься от
клиента. все критически действия по созданию,подтверждению,отмене или смене статуса будут проверятся  авторизацией,валидностью состояния и будут
идемпотентными по возможности,чтобы при создании повторного вызова не создавали конфликтов. 

Сама экономика CRUD
READ-самая дешевая но и самая частая.максимальная оптимизация,кешируемость и масштабность.
CREATE и UPDATE -дорогие,меняют истину,исполнять атомарно и ограничивать количество бизнес-правилами.
DELETE- самый дорогой в долгосрочной перспективе,стоимость-риск потери данных и доверия.  должны быть многоступенчатые барьеры для удаления(подтверждение
мягкое удаление,период ожидания,окончательное очищение).

Временное измерение CRUD. это само признание того что данные имеют историю.UPDATE И DELETE- стирают историю.

Event Sourcing или Immutable-ландшафт,где состояние не перезаписывается а наращивается слоями и удаление это не добавление нового события-инвалидатора.Они
хранят историю изменений как первичную истину.
то есть просто поле users с полем email переходит в состояние таблицы events, в котором каждая запись это зафиксированный факт где user зарегистрировался
потом изменил емейл и удалил запись:  UserRegistered, EmailChanged, UserDeactivated. эти поля неизменяемые и они только накапливаются.так же само
состояние почты пользователя это будет результатом действий с начала и до самого конца:
изначально пустое поле-->потом применили UserRegistered с одним email a@a.com--->потом применили UserChanged на a@b.com ----> и состояние стало{email:'a@b.com'}.
Update означает не перезапись а добавление нового события-факта.происходит не замена x на y, а z изменил атрибут x на y. и это просто фиксируется в
событии как часть контекста.
DELETE будет не удалением а добавлением события-инвалидатора. Здесь будет фиксироваться событие UserDeleted или еще как нибудь и вся предыстория
пользователя,все что происходило с аккаунтом,все изменения будет оставаться в логах навсегда. но сама сущность просто переходит в неактивное состояние. и
после если что можно добавить событие которое отменяет удаление. 
И при таком раскладе время будет становится параметром по которому можно переходить в различные состояния на любой момент из причинно-следственных фактов.
и каждое изменение будет иметь автора,временную метку,контекст и поимеет всех остальных если понадобится.
Архитектура на Запись и Чтение(CQRS)-это дополнение Event Sourcing. Команды  на запись только добавляют новые события в журнал,запросы работают с проекциями, специально оптимизированными представлениями данных, построенными из накопленных событий.Это разделение позволяет масштабировать модели чтения и записи.

Состояние - это само по себе центральное понятие в CRUD.
Create - это инициализация всей  машины состояний. Я перевожу машину из абстрактного и несуществующего понятия в конкретное,физическое  и при создании items и status мы запускаем циклы с установкой начального состояния. оно может быть DRAFT (черновиком) или сразу принятым в работу(NEW).Create создает саму начальную точку на оси возможных переходов и она будет определять поведение сущности в будущем.

READ - это отдельный скриншот в моменте состояния. при запросе GET мы получаем состояние в котором находится сущность сейчас и все её  указанные атрибуты.само время формирования ответа между сервером и моментом получения клиентом всей нужной инфы- состояние может изменится и READ может давать только приближенный истину. и в таких случаях это приводит к использованию меток типа updated_at, или что-то наподобие этого.

UPDATE - будет попыткой перевода и изменения состояния сущности. при вызове PATCH мы изменяем и состояние и возможно существующие его атрибуты но, допустимо далеко не все изменения. например заказы которые уже завершены нельзя перевести в новые,потому что это будет нарушать физическую логику,либо, что либо что может нарушить финансовую отчетность,изменение цен в завершенных состояниях(заказах). 
UPDATE проверяет состояние и читает status, проверяет разрешен ли переход который мы запросили  из конкретного состояния.возможно допустимое разрешение изменения заказов в ихних состояниях через внешний конфигурируемый workflow а не if-else/,и совершение самого перехода с учетом всех побочных эффектов,например: меняется ли статус,меняются ли атрибуты,запускаются ли побочные эффекты при переходе в другое состояние и разные связные действия в других бд в соответствии с принятым решением.

DELETE - будет финальным переходом в терминальное состояние DELETED или DOES_NOT_EXIST. Но физическое удаление это само по себе стирание истории и в реальности,в реальных системах DELETE это почти всегда мягкий переход в SOFT_DELETED или INACTIVE. эти состояния такие же полноценные в машине просто из них уже нет никаких переходов обратно в активную жизнь или какое либо "воскрешение из мертвых".Он сам по себе должен проверять нет ли зависимых сущностей которые могут блокировать удаление,это  проверка ценностей. так эе выполнять каскадные переходы   для зависимых. и запускать все clean-up процессы на фоне по типу уведомлений об удалении для админов,само удаление через N дней.
TODO:  RESTORE команда.

В самом ядре для каждой сущности есть модель её состояния.
Это либо поле со статусом и типом в бд и в коде,либо таблица изменений,разрешенных в конфигурации или в бд,либо библиотека или фреймворк где объявляется состояния,переходы и колбэки. и все эти операции изменяющие сущность(CREATE,UPDATE,DELETE),система задает вопросы.


Идемпотентность:

Это само свойство операции,которое определяет как система ведет себя в условиях нестабильной сети,таймаутов,повторных отправках и само собой человеческих ошибках. это та операция,которую мы повторяем по миллион раз причем безопасно с одним и тем же входным сигналом а результат все один и тот же,без каких либо изменений в базах системы и её состоянии,например заменить одну букву на другую в своем никнейм и и сто раз нажать кнопку сохранить. 

то есть состояние системы будет абсолютно идентична и одинаковая,как после первого успешного выполнения операций так и после любого количества её повторений.
CRUD-операции здесь это мутации состояния и любая неидемпотентная мутация приводит к искажению данных,к нарушению системы как таковой.
CREATE(POST) - врожденно неидемпотентен.и его семантика это создать новый ресурс.и отправляешь два одинаковых запроса POST/users с данными,и в реализации получаем два юзера с одинаковыми данными,что будет нарушать уникальность,или выдаст результат одного юзера а второй с выводом ошибки по типу "уже существует",то есть один запрос прошел,второй упал. и чтобы сделать CREATE идемпотентным используется архитектура. запускается идемпотентность через уникальный ключ запроса(idempotency Key). когда клиент при первом вызове генерирует уникальный ключ и он будет заносится в заголовок запроса,сервер получает запрос с этим ключом,и проверяет повтор проверки с этим ключом.логи проверки заносятся в хранилище, и если ключ найден сервер не будет выполнять операцию заново и просто будет возвращать тот же самый ответ включая весь статус и заголовки с телом.это будет требовать дисциплины на счет генерации ключей и дисциплины от сервера на счет ихнего хранения для определенного количества заданного времени.

Альтернатива-семантическая идемпотентность на основе бизнес-ключа.В этом подходе операция CREATE интерпретируется не как "создать нового пользователя сейчас",а как "гарантировать существование пользователя с данными X". Если пользователь с таким email(бизнес-ключом) уже существует,то повторный вызов возвращает успех или конфликт,в зависимости от семантики API, не создавая дубликата и не меняя состояние системы,и так операция становится идемпотентной по своей бизнес-логике.

При регистрации нового юзера ,и если такой емейл уже есть в базе,то выводится код ошибки или конфликта и сам статус в зависимости от семантики.и операция будет идемпотентна в своей манере и природе.потому что повторный вызов с этим емейл не будет менять состояние системы.
READ (GET)-он сам идемпотентен по определению протокола HTTP, так как предназначен только для получения данных и при повторном чтении мы ожидаем все те же данные, что и при первом. Однако на практике GET-запрос может иметь побочные эффекты как запись логов аудита или увеличивать счетчик аналитики.теоретически такой вызов уже что-то меняет в системе. 
Строго говоря GET с побочными эффектами нарушает не только идемпотентность, но и ключевую договорённость HTTP о том,что этот метод является безопасным и только наблюдающим.
UPDATE - очень важное различие между PUT и PATCH с точки зрения семантики.
При повторном запросе PUT  просто снова установит ресурс в тоже самое состояние.Он будет идемпотентным,то есть сервер должен принять весь новый образ без ресурса и валидировать его  и заменить старый. может возникнуть конфликт при отправке,потому то отправка нужна всех полей и может быть опасно при конкурентном доступе,потому что может быть потеря изменений,если между чтением и записью обновится ресурс.
Идемпотентность PATCH не гарантируется спецификацией HTTP и зависит от формата и семантики передаваемых изменений. Например, формат JSON Merge Patch(передача части объекта) по своей природе идемпотентен для операций замены значений. В то время как PATCH-запрос, содержащий операцию инкремента счётчика, идемпотентным не является.
Мы можем увеличить счетчик например. но если изменения будут в качестве новых значений для полей.В случае JSON Merge Patch или JSON Patch-операции replace, то такая операция,она может быть идемпотентной.

Если отправить запрос ещё раз, email просто снова станет new@mail.com. Но никаких гарантий от протокола нет,всё держится только на том, как это реализовано на сервере и в самом формате патча.


и в использовании PATCH с семантикой- больше избегают или предпочитают  использовать идемпотентные ключи поверх него.
DELETE - идемпотентен и его семантика после первого успешного запроса на удаление и после выполнения,повторный вызов delete не должен вызывать ошибку как "ресурс не найден" как проблему. состояние системы после первого запроса и после десятого будет идентичным: ресурса нет. он либо возвращает 200 либо 404 и оба исхода будут корректными с точки зрения идемпотентности,потому что состояние не изменилось в системе от повторного вызова.

защита будет выполнением мутирующей операции внутри транзакции бд и начинать её проверку текущего состояния,при наличии юзера с таким же емейл, мы откатываемся и возвращаем конфликт,и эта операция будет идемпотентной в рамках этой единой сессии в бд.
в хранилище обработанных ключей idempotency Key Storage - он будет центральным механизмом для сквозной идемпотентности,то есть при получении запроса с проверкой идемпотентности ключа,система  вставит этот ключ в отдельную таблицу или в Redis со своим условием.и важно чтобы вставка ключа и его проверка была в рамках транзакции с основной операцией,иначе в двух одновременных запросах оба увидят что ключа нет и оба выполнят операцию.Idempotency Key решает проблему идемпотентности на уровне одного HTTP-запроса.

Saga Pattern решает проблему на уровне распределённой бизнес-транзакции, состоящей из множества шагов, через механизм компенсирующих операций.
И для компенсирующих транзакций (Saga Pattern) есть операция где полная идемпотентность невозможно и используется подход с компенсациями. если операция А уже выполнена,а повторный запрос пришел из тайм-аута,система не выполняет операцию А снова, а проводит проверку состояния,получилось ли осуществить действие А и продолжит оставшуюся часть потока,если такой есть и требуется.

Согласованность и целостность  системы должны находится в логичном и взаимосогласованном состоянии по отношению к той реальности которую они моделируют и обслуживают.то есть это правила по которым все данные могут лежать в файлах и подчиняются жестким ограничениям, которые проверяются при попытке записи:внешние ключи,уникальность и проверки CHECK. то есть тут уже нету связи с кодом,а только к ключам,уникальности и условиям и при попытке внесении новой строки в  файл, происходит создание отдельного индексного файла и поиск индекса уже производится по этому файлу,поиск того ,что мы задаем в запросе, в нашем файле,и сам индекс в запросе так же. 

И при обнаружении того что мы указали в поиске он выполняет следующие команды,используя наши "ключи" в запросе как ориентир.Уникальностью  ограничений является то,что все записи в файле проиндексированы и поиск по запросу добавления новой записи в файл, будет проходить исключительно через анализ и чтение всех индексов,проверка на наличие,и если ответ положительный ,ответ что такая запись уже есть,она просто не заносится в существующий файл,потому что дважды записать один и тот же номер или занести один и тот же емейл нельзя. и при проверке в требуемом файле(CHECK) происходит математические проверки.и при согласованности,если я меняю несколько файлов они будут меняться все сразу. 

Но перед всеми изменениями,база записывает все планируемые изменения отдельно,в отдельный журнал,он пишется синхронно и последовательно(WAL Write-Ahead Log). 

и после этого база меняет файлы.
и если в процессе изменений файлов пошел сбой,база смотрит журнал,видит записи,сколько и какие,проверяет какие выполнены и сколько из списка,она откатывает выполненную операцию используя информацию из журнала или доделывает вторую.систем придерживается атомарности, она возвращается либо в состояние до перевода либо после перевода,но она никогда не остается в промежуточном. При исполнении одной транзакции ,другие не должны видеть её незавершенных изменений,то есть происходит полная изоляция. они либо наблюдают старые данные либо совершившиеся новые и только после того как транзакция закончится и запишет все в основные файлы.И конкурентность здесь достигается через версионирование строк или блокировку.
БД физически хранит старую и новую версию чтобы одни транзакции видели ту версию по которой они ориентируются для себя.

В блокировке-все организуется через структуры в памяти(lock manager),которые следят кто и какую строку или таблицу заблокировал


Целостность-это последний рубеж,низкоуровневый фильтр мусора в СУБД, который отлавливает два одинаковых email,заказ на несуществующий товар.Это статический страж правильности данных.
А вот согласованность-это уже про "правильность в движении".Когда десять транзакций пытаются одновременно обновить одни и те же строки, согласованность следит,чтобы данные не потеряли логику. Она гарантирует, что в условиях параллельного хаоса данные останутся осмысленными и непротиворечивыми.Целостность-это декларация того, как данные должны выглядеть (все email уникальны) а согласованность,будет механизмом, который обеспечит то, что они будут так выглядеть даже при максимальной нагрузке.


С  внешними ключами которые работают как декларация зависимости и защитой от аварий,уникальными ограничениями которые гарантируют




Социальные аспекты CRUD:
в системе всегда работают несколько пользователей,или заангажировано несколько лиц которые связаны и другими таблицами или системами.Когда мой  Update поля "статус заказа" триггерит уведомление для логиста,и для менеджера и включается поле начисления бонусов при оформлении n-нного количества заказов.
и например мой Delete файла может сломать ссылку в документе коллеги.и поэтому CRUD редко заканчивается на уровне одной таблицы в базе.это всегда может быть
узлом в сети процессов.
Event-Driven Architecture порождает UserUpdatedEvent,OrderDeletedEvent--->Чьи миры затронет это действие? Кого нужно уведомить? Что может сломаться? 
CRUD-операции редко изолированы. В сложных системах они имеют побочные эффекты и порождают доменные события (например, OrderCreated, UserEmailChanged). Эти события запускают процессы в других частях системы: уведомляют пользователей, обновляют поисковые индексы, считают аналитику. Проектируя API, необходимо явно учитывать эту сеть зависимостей."




 
Для read,update и delete это обычно прочитал дважды получил то же, удалил дважды и запись уже удалена. Для Create-нет.Два одинаковых POST-запроса создадут
две одинаковые записи,в Rest для идемпотентности Update используют PUT вместо PATCH,потому что PUT заменяет весь ресурс,а PATCH частичное обновление.для
защиты от дублирования сетевые повторы, двойные клики используют idempotency keys уникальный ключ, который клиент отправляет с запросом,сервер кэширует
результат выполнения по этому ключу и на повторный запрос с тем же ключом возвращает тот же ответ, не выполняя операцию снова.
и каждая crud операция будет менять состояние системы. так же паттерны применяются для пользовательского интерфейса. валидация данных на 3х уровнях:
на клиенте(для UX)
нв уровне API(для формальной проверки типов и форматов,Pydantic схемы)
База данных служит последним рубежом защиты целостности. Её механизмы- первичные ключи (PRIMARY KEY), ограничения уникальности (UNIQUE), проверки (CHECK) и внешние ключи (FOREIGN KEY) отсекают некорректные данные, которые могли пройти валидацию на уровне API.













Производительность READ зависит от индексов,каждое поле по которому происходит WHERE,ORDER BY,JOIN ----должно быть проиндексировано,но если индексы замедляют insert i update потому что их нужно поддерживать--нужно  балансировать
Транзакционность-все связанные изменения в рамках одной операции--только в одной и единой транзакции----Списание с одного счета-зачисление на
другой---через BEGIN.....COMMIT(с read committed достаточно)


Пагинация и фильтрация не только UX-требование,но и критически важный инструмент для производительности Read операций,предотвращающий перегрузку сервера и сети

функция обновления (по id)
функция удаления (по id)

engine-глобальное подключение 
session-одно подключение конкретно
engine создаётся один раз при старте.
Session- для каждого HTTP-запроса своя.

не пишем базу данных внутри main файла. ---это будет зависимость. паттерны,сервисы,чистый код и тд..... это запрещено
отдельный database.py файл 
Презентационный слой API/UI --> бизнес-логика Services --> слой данных Repositories  --> База данных

async with session.begin(): для атомарных операций
запрещены f-строки --sql инъекции

всегда пагинация
        async def get_items(db, skip: int = 0, limit: int = 100):
    return await db.execute(
        select(Item).offset(skip).limit(limit)
    )



без пула при 100 параллельных запросах упадёт БД.
Контекстные менеджеры для сессий ---обязательно  with:

expire_on_commit=False - настройка,которая решает проблему detached objects, но может использовать устаревшие данные в долгоживущих сессиях:
Без этой настройки после await session.commit() все объекты становятся неактивными.если потом обратиться к user.email -будет ошибка.
С этой настройкой- объекты остаются доступны.

await session.refresh()- после добавления нового объекта.при создании нового юзера,в объекте user, не будет id,присвоенный  от базы

lazy="raise"-ставить на отношениях в моделях,она заставляет явно указать,какие связанные данные нужно загружать через selectinload(),joinload(),вместо ленивой загрузки. и использование lazy='raise',напрямую поддерживает crud-экономику предотвращая N+1 запросы.

раз в месяц смотреть логи-сколько соединений в пуле, сколько ждут.
если постоянно есть ожидание-увеличить pool_size.если пул почти пустой-уменьшить.

подключение к разным бд=отдельные engine:
Если проект работает с основной БД и, например, Redis:создаю ДВА engine в database.py,два sessionmaker,две зависимости get_db() и get_redis()

В development можно без SSL, в production обязательно

В production echo=False, иначе логи забьются SQL запросами

Connection string -не хардкодить:
бкз "postgresql://user:pass@localhost/db" в коде
выносить в .env,читать через os.getenv()


При shutdown закрывать engine,атооооооо останутся незакрытые соединения
@app.on_event("shutdown")
async def shutdown():
    await engine.dispose()

datetime в UTC,все даты в бд  в UTC,конвертация в локальное время только при отображении пользователю будут проблемы с летним временем, переездами......


soft delete вместо DELETE,без удаление записи физически из бд,
сделать колонку "deleted_at" или что-то.
Удаление=проставление timestamp. 
Восстановление=очистка поля.чтобы не потерять историю данных.

Раз в неделю смотреть логи бд по медленным запросам >100ms

хэшировать перед сохранением пароли

bulk insert/update:
session.bulk_insert_mappings()-в 100 раз быстрее.


SQLAlchemy использует prepared statements их автоматически.


Если планируется нагрузка,то настроить read replicas сразу,так как последующее внедрение реплик в работающую систему будет сложной и рискованной задачей.

Failover стратегия:
если основная бд упала-иметь скрипт переключения на replica.тестировать раз в квартал.


при балансе счета,настройки безопасности, для критичных данных вести лог кто и когда что изменил на уровне бд триггерами


задача connection,спит 5 минут ждёт API одновременно HTTP запросы не могут получить connection из пула в таймаут.
для фоновых задач отдельный engine с pool_size=1 или connection outside pool.


при проверке есть ли email в бд, и если нет,создаю-всего 2 запроса одновременно проверяют и видят НЕТ и оба создают. UNIQUE constraint в БД ловит, но один
пользователь получает ошибку "email уже занят", хотя только что его вводил. Надо ловить IntegrityError и retry


при long polling запросы висят 30-60 секунд забирают connection из пула. БД столько не тянет.нужно WebSockets или отдельный сервер/протокол